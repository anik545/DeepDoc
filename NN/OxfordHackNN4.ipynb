{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Cardiac Arrhythmia Classification\n",
    "\n",
    "First we need to import the dependencies - **pandas** to pre-process and clean up the input data and **numpy** for linear algebra and matrix multiplication and  **TensorFlow** to build and train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mukulrathi/anaconda/envs/dltestenv/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to use **pandas** to input the data (a text file) and clean up the dataset by accounting for missing feature values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('arrhythmia.data.txt')\n",
    "dataset = dataset.replace('?', 0)\n",
    "#dataset.convert_objects(convert_numeric=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the dataset, to eliminate bias in training and ensure training and testing data come from the same distribution. Having done this, we split the dataset into input features *X* and labels *Y* and process them so they are ready to be input to the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#randomly shuffle the data \n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#split into input features and labels\n",
    "X = dataset.iloc[:,0:279] \n",
    "Y = dataset.iloc[:,279:]\n",
    "\n",
    "#convert each of the dataframe objects to a matrix (2D array)\n",
    "X = X.as_matrix()\n",
    "Y = Y.as_matrix()\n",
    "\n",
    "#Convert the labels vector into a one-hot encoding matrix\n",
    "Y-=1\n",
    "Y = np.squeeze(np.eye(16)[Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the hyperparameters (\"tuning knobs\") for the neural network - these are parameters we can tune to improve the performance of our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters={}\n",
    "hyperparameters[\"num_epochs\"] = 100 #number of passes through the training set\n",
    "hyperparameters[\"batch_size\"] = 128 #number of examples trained upon in each step of training\n",
    "hyperparameters[\"learning_rate\"] = 1e-3\n",
    "hyperparameters[\"n_x\"] = 279 #number of input features\n",
    "hyperparameters[\"n_y\"] = 16 #number of classes\n",
    "hyperparameters[\"layers_units\"] = [1024, 512, 512,512,256,256,128,32,16] #number of neurons in each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the dataset into 3 sections - the training data which the network is fed to train upon, the cross-validation dataset which is used to tune the hyperparameters, and the test dataset which provided an unbiased benchmark for the model's performance. There are 471 examples in total and we use a ~70:15:15 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainTestDevSets = {}\n",
    "\n",
    "TrainTestDevSets[\"X_train\"] = X[:330,:]\n",
    "TrainTestDevSets[\"Y_train\"] = Y[:330,:]\n",
    "\n",
    "TrainTestDevSets[\"X_dev\"] = X[330:400,:]\n",
    "TrainTestDevSets[\"Y_dev\"] = Y[330:400,:]\n",
    "\n",
    "TrainTestDevSets[\"X_test\"] = X[400:,:]\n",
    "TrainTestDevSets[\"Y_test\"] = Y[400:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a helper function to initialise the weights and biases for a layer in the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialise_parameters(weight_shape, bias_shape):\n",
    "    weight = tf.Variable(tf.truncated_normal(weight_shape, stddev=0.1))\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=bias_shape))\n",
    "    return weight, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define another helper function to initialise a layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(X, num_units,layer_num):\n",
    "    with tf.name_scope('fc'+str(layer_num)):\n",
    "        input_dim = int(X.shape[1])\n",
    "        weight_shape = [input_dim,num_units]\n",
    "        bias_shape = [num_units]\n",
    "        Weight, bias = initialise_parameters(weight_shape,bias_shape)\n",
    "        activation = tf.nn.relu(tf.matmul(X, Weight) + bias)\n",
    "        #tf.summary.histogram(\"W_fc\" + str(layer_num), Weight)\n",
    "        #tf.summary.histogram(\"b_fc\" + str(layer_num), bias)\n",
    "        #tf.summary.histogram(\"Activation_fc\"+ str(layer_num), activation)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a helper function that initialises the TensorFlow computation graph for a neural network by looping through the list *layers_units* that initialises the neural network with the correct number of layers and hidden units in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X,layers_units):\n",
    "    self = fully_connected_layer(X,layers_units[0],1)\n",
    "    for i in range(1,len(layers_units)-1):\n",
    "        self = fully_connected_layer(self,layers_units[i],i+1)\n",
    "    with tf.name_scope('fc'+str(len(layers_units))):\n",
    "        input_dim = int(self.shape[1])\n",
    "        weight_shape = [input_dim,layers_units[len(layers_units)-1]]\n",
    "        bias_shape = [layers_units[len(layers_units)-1]]\n",
    "        Weight, bias = initialise_parameters(weight_shape,bias_shape)\n",
    "        self = tf.matmul(self, Weight) + bias\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the cost function - this is the objective function the neural network aims to minimise as it learns through training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_function(ZL,Y):\n",
    "    logits = tf.transpose(ZL)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels,logits=logits))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the evaluation metric - the accuracy of the neural network - that we will use to evaluate the performance of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_accuracy(ZL,Y):\n",
    "    correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(ZL,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    #tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax function normalises the outputs of the final layers so they sum to 1 and represent the probability of the data being the given class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x-= np.max(x,axis=1,keepdims=True)\n",
    "    x = np.exp(x)\n",
    "    x/= np.sum(x,axis=1,keepdims=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have defined our helper functions, we can use TensorFlow to create the neural network computation graph and then train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(hyperparameters,TrainTestDevSets):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    num_epochs = hyperparameters[\"num_epochs\"]\n",
    "    batch_size = hyperparameters[\"batch_size\"]\n",
    "    learning_rate = hyperparameters[\"learning_rate\"]\n",
    "    layers_units = hyperparameters[\"layers_units\"]\n",
    "\n",
    "    n_x = hyperparameters[\"n_x\"]\n",
    "    n_y = hyperparameters[\"n_y\"]\n",
    "    X_train = TrainTestDevSets[\"X_train\"]\n",
    "    Y_train = TrainTestDevSets[\"Y_train\"]\n",
    "    X_dev = TrainTestDevSets[\"X_dev\"]\n",
    "    Y_dev = TrainTestDevSets[\"Y_dev\"]\n",
    "    X_test = TrainTestDevSets[\"X_test\"]\n",
    "    Y_test = TrainTestDevSets[\"Y_test\"]\n",
    "\n",
    "    \n",
    "    X = tf.placeholder(tf.float32,[None,n_x])\n",
    "    Y = tf.placeholder(tf.float32,[None,n_y])\n",
    "    ZL = forward_propagation(X,layers_units)\n",
    "       \n",
    "    cost = cost_function(ZL,Y)\n",
    "    \n",
    "    accuracy = eval_accuracy(ZL,Y)\n",
    "   \n",
    "    optimiser = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    #summaries = tf.summary.merge_all()\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        #summary_writer = tf.summary.FileWriter(\"temp/training/\",tf.get_default_graph())\n",
    "        print(\"Training the model: \")\n",
    "        for epoch in range (num_epochs):\n",
    "            for i in range(0,X_train.shape[1]//batch_size):\n",
    "                #get the next minibatch to train on\n",
    "                X_train_minibatch = X_train[:,i*batch_size:(i+1)*batch_size]\n",
    "                Y_train_minibatch = Y_train[:,i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "                sess.run([optimiser], feed_dict={X: X_train, Y: Y_train})\n",
    "                #summary_writer.add_summary(summary, epoch)\n",
    "                train_accuracy = accuracy.eval(feed_dict={X: X_train, Y: Y_train})\n",
    "                print('Epoch '+ str(epoch) +  ': train accuracy = ' + str(train_accuracy))\n",
    "                dev_accuracy = accuracy.eval(feed_dict={X: X_dev, Y: Y_dev})\n",
    "                print('Dev accuracy = ' + str(dev_accuracy))\n",
    "        print(\"Training complete!\")   \n",
    "        test_accuracy = accuracy.eval(feed_dict={X: X_test, Y: Y_test})\n",
    "        print('The test accuracy = ' + str(test_accuracy))\n",
    "        Y_predict = ZL.eval({X:X_test})\n",
    "        Y_predict = pd.DataFrame(softmax(Y_predict))\n",
    "        Y_test = pd.DataFrame(Y_test)\n",
    "        return Y_predict,Y_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model: \n",
      "Epoch 0: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 0: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 1: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 1: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 2: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 2: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 3: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 3: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 4: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 4: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 5: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 5: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 6: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 6: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 7: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 7: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 8: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 8: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 9: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 9: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 10: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 10: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 11: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 11: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 12: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 12: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 13: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 13: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 14: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 14: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 15: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 15: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 16: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 16: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 17: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 17: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 18: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 18: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 19: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 19: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 20: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 20: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 21: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 21: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 22: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 22: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 23: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 23: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 24: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 24: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 25: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 25: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 26: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 26: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 27: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 27: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 28: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 28: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 29: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 29: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 30: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 30: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 31: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 31: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 32: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 32: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 33: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 33: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 34: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 34: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 35: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 35: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 36: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 36: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 37: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 37: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 38: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 38: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 39: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 39: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 40: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 40: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 41: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 41: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 42: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 42: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 43: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 43: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 44: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 44: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 45: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 45: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 46: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 46: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 47: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 47: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 48: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 48: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 49: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 49: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 50: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 50: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 51: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 51: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 52: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 52: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 53: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 53: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 54: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 54: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 55: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 55: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 56: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 56: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 57: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 57: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 58: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 58: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 59: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 59: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 60: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 60: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 61: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 61: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 62: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 62: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 63: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 63: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 64: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 64: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 65: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 65: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 66: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 66: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 67: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 67: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 68: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 68: train accuracy = 0.527273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev accuracy = 0.542857\n",
      "Epoch 69: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 69: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 70: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 70: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 71: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 71: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 72: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 72: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 73: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 73: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 74: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 74: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 75: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 75: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 76: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 76: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 77: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 77: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 78: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 78: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 79: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 79: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 80: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 80: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 81: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 81: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 82: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 82: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 83: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 83: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 84: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 84: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 85: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 85: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 86: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 86: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 87: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 87: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 88: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 88: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 89: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 89: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 90: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 90: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 91: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 91: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 92: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 92: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 93: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 93: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 94: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 94: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 95: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 95: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 96: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 96: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 97: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 97: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 98: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 98: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 99: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Epoch 99: train accuracy = 0.527273\n",
      "Dev accuracy = 0.542857\n",
      "Training complete!\n",
      "The test accuracy = 0.647059\n"
     ]
    }
   ],
   "source": [
    "Y_predict,Y_test = train_model(hyperparameters,TrainTestDevSets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the neural network achieves an accuracy of ~65%. This is especially impressive given that the orginal dataset was difficult to parse and had to be cleaned since there were a lot of missing feature values.\n",
    "For context, randomly guessing the class would result in a 1/16 probability of success i.e. a ~6% accuracy.\n",
    "\n",
    "Finally we save the results to csv files for visualisation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_predict.to_csv('NN_predictions',encoding='utf-8',index=False)\n",
    "Y_test.to_csv('NN_test',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
